{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.covariance as cov\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ggplot import *\n",
    "\n",
    "train_original = pd.DataFrame.from_csv(\"cleaned_train.csv\")\n",
    "data = train_original.copy()\n",
    "\n",
    "apply_price_log = True\n",
    "log_method = np.log\n",
    "exp_method = np.exp\n",
    "if apply_price_log:\n",
    "    data['SalePrice'] = (data['SalePrice']).map(log_method) #'LOGLOGLO'\n",
    "\n",
    "train = data.as_matrix()\n",
    "names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop features with low variance\n",
    "import sklearn.feature_selection as sel\n",
    "\n",
    "thredsh = sel.VarianceThreshold(threshold=0.0) # comparing with plots  0.003 seems to be a good threshold; no it doesn't. dont do it\n",
    "thredsh.fit(train)\n",
    "deselected = ~thredsh.get_support()\n",
    "data = data.drop(names[deselected],axis=1)\n",
    "\n",
    "# regenerate matrix\n",
    "train = data.as_matrix()\n",
    "names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pre\n",
    "\n",
    "# scale all\n",
    "scaler = pre.RobustScaler()# StandardScaler sucks\n",
    "train = scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "labels = train[:,0]\n",
    "features = train[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We learned: neural networks suck balls at predicting house prices. Don't use your brain when buing a house. As you tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "bag_contents = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=1800,max_leaf_nodes=15,learning_rate=0.005, random_state=1337, loss='ls')\n",
    "\n",
    "bag = ensemble.BaggingRegressor(base_estimator=bag_contents, n_jobs=4, random_state=1337)\n",
    "\n",
    "#scores = cross_val_score(fitter,features,labels,cv=2,scoring='neg_mean_squared_error',n_jobs=4)\n",
    "#print(\"RMSE: %0.5f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=Lasso(alpha=0.005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=4, oob_score=False,\n",
       "         random_state=1337, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.fit(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'neg_mean_squared_error'\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#mean_squared_error(y_test,bag.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importance = bag.feature_importances_\n",
    "#sort = np.argsort(importance)[::-1]\n",
    "#list(zip(importance[sort],names[1:][sort]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_predict = pd.DataFrame.from_csv(\"cleaned_test.csv\")\n",
    "# apply transformations\n",
    "to_predict = to_predict.drop(train_original.columns[deselected],axis=1)\n",
    "to_predict_matrix = to_predict.as_matrix()\n",
    "to_predict_matrix = scaler.transform(to_predict_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = to_predict_matrix[:,1:]\n",
    "labels = bag.predict(features)\n",
    "prices = scaler.inverse_transform(np.insert(features,0,labels,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_predict['SalePrice'] = prices\n",
    "if apply_price_log:\n",
    "    to_predict['SalePrice'] = (to_predict['SalePrice']).map(exp_method)\n",
    "to_predict[['SalePrice']].to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
